import os
import sys
from config.settings import Settings
from core.document_loader import DocumentLoader
from core.text_processor import  TextProcessor
from core.vector_store import VectorStoreManager
from core.qa_engine import QAEngine
from core.qa_engine  import *
from utils.logger import get_logger,setup_logger
from models.deepseek_models import DeepSeekLLM
from models.huggingface_models import HuggingFaceEmbedding
from utils.exceptions import RAGSystemError, ConfigurationError, SearchError
from typing import List, Optional

class RAGSystem:
    """
    RAGç³»ç»Ÿä¸»ç±»
    """
    def __init__(self,config_path:Optional[str]= None):
        #è®¾ç½®æ—¥å¿—
        self.logger= setup_logger()

        #åŠ è½½é…ç½®
        self.settings = Settings(config_path)

        if not self.settings.validate_config():
            raise ConfigurationError("é…ç½®éªŒè¯å¤±è´¥")

        #åˆå§‹åŒ–ç»„ä»¶
        self.embeddings_model = None
        self.llm_model = None
        self.vector_store_manager = None
        self.qa_engine = None

        self.logger.info("RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _validata_custom_config(self)-> bool:
        """
        è‡ªå®šä¹‰é…ç½®éªŒè¯
        """
        # æ£€æŸ¥LLMçš„APIå¯†é’¥
        errors = []
        if self.settings.llm_config.provider == "deepseek" and not self.settings.llm_config.api_key:
            errors.append("ç¼ºå°‘DeepSeekçš„APIå¯†é’¥")

        # æ£€æŸ¥æ–‡æ¡£è·¯å¾„
        if not os.path.exists(self.settings.docs_path):
            errors.append(f"æ–‡æ¡£è·¯å¾„ä¸å­˜åœ¨: {self.settings.docs_path}")

        if errors:
            for error in errors:
                print(f"é…ç½®é”™è¯¯: {error}")
            return False

        return True

    def _initialize_models(self):
        """
        åˆå§‹åŒ–æ¨¡å‹
        """
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        if self.settings.embedding_config.provider == "huggingface":
            self.logger.info("æ­£åœ¨åŠ è½½HuggingFaceåµŒå…¥æ¨¡å‹ï¼ˆé¦–æ¬¡åŠ è½½éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
            self.embedding_model = HuggingFaceEmbedding(self.settings.embedding_config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åµŒå…¥æ¨¡å‹: {self.settings.embedding_config.provider}")

        #åˆå§‹åŒ–LLMæ¨¡å‹
        if self.settings.llm_config.provider == "deepseek":
            self.llm_model = DeepSeekLLM(self.settings.llm_config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæ¨¡å‹: {self.settings.llm_config.provider}")
        self.logger.info("æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

    def build_knowledge_base(self, force_rebuild: bool = False):
        self.logger.info("å¼€å§‹æ„å»ºçŸ¥è¯†åº“")
        self._initialize_models()  # ç¡®ä¿æ¨¡å‹å…ˆåˆå§‹åŒ–

        # ä¿®å¤åˆ¤æ–­é€»è¾‘ï¼šå¦‚æœå­˜åœ¨ä¸”ä¸å¼ºåˆ¶é‡å»ºï¼Œåˆ™åŠ è½½ï¼›å¦åˆ™åˆ›å»ºæ–°çš„
        if os.path.exists(self.settings.vector_store_config.persist_directory) and not force_rebuild:
            self.logger.info("å‘ç°å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“ï¼Œç›´æ¥åŠ è½½")
            self._load_existing_knowledge_base()
        else:
            # åŸä»£ç é”™è¯¯åœ°æ‰“å°äº†"å‘ç°å·²å­˜åœ¨..."ï¼Œè¿™é‡Œä¿®æ­£æ—¥å¿—
            self.logger.info("æœªå‘ç°å‘é‡æ•°æ®åº“æˆ–éœ€è¦å¼ºåˆ¶é‡å»ºï¼Œå¼€å§‹åˆ›å»ºæ–°çŸ¥è¯†åº“")
            self._create_new_knowledge_base()
        self.logger.info("çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
        if not self.vector_store_manager or not self.qa_engine:
            raise RAGSystemError("çŸ¥è¯†åº“æ„å»ºä¸å®Œæ•´ï¼Œå‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")

    def _load_existing_knowledge_base(self):
        self.vector_store_manager = VectorStoreManager(
            self.embedding_model,
            self.settings.vector_store_config
        )
        # è·å–å‘é‡å­˜å‚¨å®ä¾‹
        self.vector_store = self.vector_store_manager.get_vector_store()
        # åŠ è½½å‘é‡æ•°æ®
        self.vector_store.load(self.settings.vector_store_config.persist_directory)
        # æ–°å¢éªŒè¯
        if not hasattr(self.vector_store, 'chroma_db') or self.vector_store.chroma_db is None:
            raise SearchError("å‘é‡å­˜å‚¨åŠ è½½å¤±è´¥ï¼Œchroma_dbæœªåˆå§‹åŒ–")

        self.qa_engine = QAEngine(
            self.llm_model,
            self.vector_store,  # ä½¿ç”¨å·²åŠ è½½çš„å‘é‡å­˜å‚¨å®ä¾‹
            self.settings.retrieval_config
        )

    def _create_new_knowledge_base(self):
        """
        åˆ›å»ºæ–°çš„çŸ¥è¯†åº“
        """
        #1.åŠ è½½æ–‡æ¡£
        loader = DocumentLoader(self.settings.docs_path)
        documents = loader.load_documents()
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½æ–‡æ¡£
        if not documents:
            raise RAGSystemError(f"æœªèƒ½ä»è·¯å¾„ {self.settings.docs_path} åŠ è½½ä»»ä½•æ–‡æ¡£")

        #2.å¤„ç†æ–‡æ¡£
        processor = TextProcessor(self.settings.processing_config)
        chunks = processor.process_documents(documents)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆchunks
        if not chunks:
            raise RAGSystemError("æ–‡æ¡£å¤„ç†åæœªç”Ÿæˆä»»ä½•æ–‡æœ¬å—")

        #3.å‘é‡åŒ–(åˆ›å»ºå‘é‡å­˜å‚¨)
        self.vector_store_manager = VectorStoreManager(
            self.embedding_model,
            self.settings.vector_store_config
        )
        vector_store = self.vector_store_manager.get_vector_store()
        vector_store.add_chunks(chunks)
        vector_store.save(self.settings.vector_store_config.persist_directory)

        #4.åˆ›å»ºQAå¼•æ“
        self.qa_engine = QAEngine(
            self.llm_model,
            vector_store,
            self.settings.retrieval_config
        )
    def answer_question(self,question:str)-> str:
        """
        å›ç­”é—®é¢˜
        """
        if not self.qa_engine:
            raise RAGSystemError("çŸ¥è¯†åº“æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨ build_knowledge_base()")
        return self.qa_engine.answer_question(question)

    def interactive_mode(self):
        """äº¤äº’å¼é—®ç­”æ¨¡å¼"""
        print("\n" + "=" * 60)
        print("ğŸ¤– LangChain RAGé—®ç­”ç³»ç»Ÿ")
        print(
            f"ğŸ“š ä½¿ç”¨æ¨¡å‹: {self.settings.llm_config.provider} - {self.settings.llm_config.model_name}")
        print(
            f"ğŸ” åµŒå…¥æ¨¡å‹: {self.settings.embedding_config.provider} - {self.settings.embedding_config.model_name}")
        print("ğŸ’¬ è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œè¾“å…¥ 'quit' é€€å‡º")
        print("=" * 60)

        sample_questions = [
            "LangSmith çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿå®ƒå¦‚ä½•æå‡ AI åº”ç”¨çš„å¯è§‚æµ‹æ€§ä¸å¯è¯„ä¼°æ€§ï¼Ÿ",
            "angChain å¦‚ä½•å¸®åŠ©å¼€å‘è€…åœ¨ä¸åŒ LLM æ¨¡å‹ä¹‹é—´åšå‡ºå¹³è¡¡å†³ç­–ï¼ˆå‡†ç¡®ç‡ã€å»¶è¿Ÿã€æˆæœ¬ï¼‰ï¼Ÿ",
            "LangChain ç”Ÿæ€ç³»ç»Ÿä¸­æœ‰å“ªäº›ä¸»è¦ç»„ä»¶ï¼Ÿå®ƒä»¬ä¹‹é—´æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ",
            "angChain çš„ä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿå®ƒå¸Œæœ›å¸®åŠ©å¼€å‘è€…è§£å†³å“ªäº›é—®é¢˜ï¼Ÿ",
            "LangChain çš„ â€œretrieverï¼ˆæ£€ç´¢å™¨ï¼‰â€ æ¥å£åœ¨ RAG åº”ç”¨ä¸­æ‰®æ¼”äº†ä»€ä¹ˆè§’è‰²ï¼Ÿ"
        ]

        print("\nğŸ” ç¤ºä¾‹é—®é¢˜:")
        for i, q in enumerate(sample_questions, 1):
            print(f"{i}. {q}")
        print()

        while True:
            try:
                question = input("ğŸ’¬ è¯·è¾“å…¥é—®é¢˜: ").strip()

                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break

                if not question:
                    continue

                print(f"\nğŸ¤” æ­£åœ¨æ€è€ƒé—®é¢˜: {question}")
                result = self.answer_question(question)

                print(f"\nğŸ¤– å›ç­”:")
                print(result.answer)

                print(f"\nğŸ“Š æ£€ç´¢ä¿¡æ¯:")
                print(f"å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
                print(f"å‚è€ƒæ–‡æ¡£æ•°é‡: {len(result.source_chunk)}")

                if result.source_chunk:
                    print("\nğŸ“š å‚è€ƒæ¥æº:")
                    for i, source in enumerate(result.source_chunk, 1):
                        source_file = source.chunk.metadata.get('source', 'æœªçŸ¥')
                        print(
                            f"{i}. {os.path.basename(source_file)} (ç›¸å…³åº¦: {source.score:.3f})")

                print("\n" + "-" * 60)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
                continue

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºRAGç³»ç»Ÿ
        rag_system = RAGSystem()

        # æ„å»ºçŸ¥è¯†åº“
        print("æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        rag_system.build_knowledge_base(force_rebuild=True)

        # å¯åŠ¨äº¤äº’æ¨¡å¼
        rag_system.interactive_mode()

    except ConfigurationError as e:
        print(f"é…ç½®é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶")
    except RAGSystemError as e:
        print(f"ç³»ç»Ÿé”™è¯¯: {e}")
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()









































